---
id: future
title: 未来趋势
sidebar_position: 8
description: 提示词未来发展和趋势分析.
---

------



## 提示词



### 从简单到结构化

GPT-3.5 的出现让人们开始真正认识大语言模型，并且开始通过一些指令型的提示词和大语言模型进行交互，我们仍然处在大语言模型的早期阶段，提示词往往是简单的、直接的，如“请帮我将下列内容翻译成某个特定语言”或“解释经济学的基本原理”。然而，随着模型的处理能力的增强，我们开始探索大语言模型的可能性，然后尝试用大语言模型来帮助解决一些更为复杂却更有价值的问题，我们开始意识到简单的提示词已经不能满足复杂任务的需求。因此，结构化的提示词应运而生。

结构化提示词不仅包含了任务的基本信息，还为模型提供了更多的上下文，使其能够更好地理解任务的本质。例如，当我们希望提供更为复杂的处理内容，应该用特殊的格式划分内容区域，这能够让大模型能好分辨出任务内容本身的描述和任务的目标内容；面对复杂的任务内容，为了提高结果的稳定，我们对任务本身进行了拆分，将一个复杂的任务拆分为一个一个子任务，然后大语言模型逐条处理以达到 `COT`的效果。这些都是目前提示词已经达到的高度，可以预测未来的场景需求会更加复杂，可能需要使用者通过更加高效的方式去告诉大语言模型自己的需求是什么，这种高效的方式并不会是一味地堆砌上下文，而是一种理解大语言模型设计模式后的实战结果。



### 从单一到组合

无论对单个提示词进行怎样的优化，其能处理的任务的复杂度和范围都是有限的。很多时候我们只有意图和预期结果，不能将这些脑子里的想法转化为完整详细的提示词，还有些情况大语言模型处理任务的中间过程依赖外部信息，这些实际的需求推动我们开始思考能否将一个提示词的输出作为下一个提示词的输入？如果可以，那么提示词与提示词的中间状态就拥有了很多的可能性。

问题答案就是组合提示词。

组合提示词可以是链式的、列举式的或者是树形的，将一个复杂的任务变成一个完整的流程，上一个提示词产生的结果，可以直接进入下一个提示词，但也可以是和用户进行交互，向用户提供选择，让用户选择结果的去向，这里存在着无限的可能性。例如，我们感觉到饥饿，但没有明确的想法去解决这个问题，那么第一个提示词可以是分析用户状态提供选择，例如自己在家做或者外出就餐，这里可以利用大语言模型分析用户表述的方式和语气，判断用户的饥饿程度，进而推荐哪种方式。假设用户的选择是外出就餐，那么下一个提示词的核心任务应该是获取外出就餐的必要信息，例如查询获取可以选择的餐厅或者菜式，然后生成选择或者结果，这取决于这个组合任务是否到这里就结束。



### 应用场景的变化

随着对大语言模型和提示词更加的了解，提示词的应用场景在发生变化，向着专业度和深度发展。最初，绝大多数用户认识和使用大语言模型，都是从大语言模型的广度开始的，希望大语言模型能够帮助解决从生活到工作各个方面的问题，例如，如何制作一道美食，解释下经济学中短缺和稀缺的区别，规划一个出行计划等等。利用大语言模型和提示词帮助我们解决这些问题，能帮助我们节省不少时间，也会产生一个疑问：假如，我是一位牙医或者律师，我能利用大语言模型和提示词做什么？这是一个从专业角度对大语言模型的思考，这个问题现在没有一个确定的答案，但是可以参考彭博社利用自己财经方面的数据构建了一个面向专业用户的大语言模型，专门帮助解决关于市场和投资相关的问题。不久的将来，会有越来越多的个人或者机构将大语言模型和提示词应用于更加专业的细分领域，面对的问题越来越具有专业性，这也要求提示词的设计从通用性向着专业性进行变化。



### 商业价值与生态系统

当人们意识到提示词确实能帮助提高生产效率的时候，自然愿意为其买单。目前市场上已经出现了提示词交易市场，提示词社区等平台，用户可以在上面创建和调试提示词，然后挂售，这类提示词无论是从专业性还是实际应用，都具有非常高的质量。

其中也不乏一些反对的声音，认为提示词应该作为一种公共资源共享，而不是作为一种售卖的商品。对于这类观点，从技术发展的角度分析，在发展阶段的早起，我认为非常合理，因为这个时候目的是为了让人们了解这项技术而不是利用新技术作为噱头进行变现。但长远来看，随着技术发展越发成熟，提示词商品价值的体现，不仅可以促进提示词的创新和分享，还可以为整个大语言模型生态系统带来巨大的价值。要知道，任何一项技术创新和发展都需要市场的支持，如果没人愿意掏腰包，那谁愿意花时间和精力去设计一个更加高质量的提示词呢？或者你凭什么从别人那里获得这个高质量的提示词？可以预见的是，未来的提示词交易体系肯定会越来越成熟，绝对不会存在类似现在开盲盒式的交易方式。



## 大语言模型

提示词的发展离不开大语言模型，本质上提示词是人类和大语言模型交互的一种手段，大语言模型的变化在时刻影响着提示词技术，我也相信这两者之间会相互影响。



### 文字到图像

OpenAI 的首席科学家 Ilya Sutskever 在接受 Nvidia 黄仁勋的访谈中，也提到大语言模型在往多模态发展，大型语言模型的能力不再局限于文本。图像处理能力使模型能够从图像中提取信息，理解图像背后的故事或情境，并生成与之相关的文本描述。例如，模型可以根据一幅画作生成与其相关的艺术评论或历史背景。语音识别和生成技术的结合使得模型能够与用户进行更为自然的对话交互，这不仅仅是文字上的交流，还包括语调、情感和语境的理解。视频内容的处理则更为复杂，因为它涉及到图像、声音和时间序列的综合理解。模型需要能够理解视频中的动作、情境和故事情节，并能够生成与之相关的描述、评论或摘要。



### 私有化模型

技术浪潮下，每个企业都在思考如何将自己现有的业务和数据与大语言模型结合，但也面临一个非常强硬的问题：内部数据不能外传。私有化模型很好地解决了这个问题，现在有非常多的大语言模型都开源了自己的代码，[HuggingFace](https://huggingface.co/) 上每天都有新的内容，无论是个人开发者还是企业都可以通过开源模型结合自己的数据创建一个属于自己的大语言模型。这种方式提供了更高的数据安全和隐私保护，企业可以在自己的私有数据上训练和微调模型，确保数据不会被外部访问，对于涉及敏感信息的行业，如金融、医疗和法律，尤为重要。同时微调技术的进步使得模型能够更好地适应特定的任务或领域，提供更为精确和专业的输出。合成训练数据的研究为模型的训练提供了更多的可能性，模型可以在合成数据上进行预训练，然后在真实数据上进行微调，这不仅可以提高模型的性能，还可以减少对真实数据的依赖。



### 数据安全

大语言模型的发展除了算法的更新以及硬件设备的升级，很重要的一方面就是训练数据集。针对训练数据集，我们可以提一个问题：

用户在使用大语言模型的时候，是否也在提供训练数据？

这个问题现在没有明确的答案，以后也不一定有，如果有人现在就告诉你有明确的答案，只有两种可能，第一种他在骗你，第二种他也不懂。现有的大语言模型的官网首页都在强调一个很重要的特性 `Safety`，无论是用户数据的安全，还是微调模型训练数据的安全，都被安排在大语言模型产品设计的第一位。但是大语言模型的发展离不开训练数据，我相信随着技术发展和市场的成熟，数据安全问题会有一个合理的解决方案（现有方案让 AI 生成训练数据，很好地思路），不一定完美，但至少能让绝大多数人接受。



## 总结

技术成熟曲线：

![Gartner_Hype_Cycle](../../../../docs/assets/2560px-Gartner_Hype_Cycle.svg.png)

对于大语言模型，如OpenAI的GPT系列，从其发展历程来看，它已经经历了技术触发阶段，因为最初的小型语言模型引起了学术界和工业界的广泛关注。随着模型规模的增大和应用的广泛推广，目前它可能已经进入或接近“峰值期望阶段”。在这个阶段，大家对大语言模型有很高的期望，认为它可以解决很多NLP问题，但同时也存在过度炒作的风险。

随着时间的推移，人们可能会发现大语言模型并不是万能的，它在某些特定任务上可能并不如专门设计的模型表现出色。这可能会导致技术进入“失望的深渊”阶段。

但是，面对一项新的技术，我们理应从积极的角度去看待而不是从悲观的角度，未来 AI 技术肯定是最重要的技术之一。能够紧跟技术发展脚步并且利用新技术创造价值，是重要的技能之一，这个技能能够帮助你在 AI 浪潮之下找到一个舒适的立足之地。
